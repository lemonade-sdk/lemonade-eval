backend: llamacpp gpu
checkpoint: Llama-3.2-1B-Instruct-GGUF
iterations: 1
output_tokens: 256
prompts:
- 'Tell me an extremely long story that starts with the following but goes from there:
  word word word word word word word word word word word word word word word word
  word word word word word word word word '
warmup_iterations: 0
