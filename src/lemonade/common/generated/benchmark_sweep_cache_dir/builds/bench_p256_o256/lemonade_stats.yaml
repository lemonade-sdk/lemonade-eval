backend: llamacpp gpu
checkpoint: Llama-3.2-1B-Instruct-GGUF
iterations: 1
max_memory_used_gbyte: 0.5004081726074219
output_tokens: 256
prefill_tokens_per_second: 5350.164057765053
prompt_tokens: 256
prompts:
- 'Tell me an extremely long story that starts with the following but goes from there:
  word word word word word word word word word word word word word word word word
  word word word word word word word word word word word word word word word word
  word word word word word word word word word word word word word word word word
  word word word word word word word word word word word word word word word word
  word word word word word word word word word word word word word word word word
  word word word word word word word word word word word word word word word word
  word word word word word word word word word word word word word word word word
  word word word word word word word word word word word word word word word word
  word word word word word word word word word word word word word word word word
  word word word word word word word word '
response_tokens: 256
seconds_to_first_token: 0.047848999999999996
token_generation_tokens_per_second: 154.25069111540122
warmup_iterations: 0
