backend: llamacpp gpu
checkpoint: Llama-3.2-1B-Instruct-GGUF
iterations: 1
max_memory_used_gbyte: 0.5004081726074219
output_tokens: 128
prefill_tokens_per_second: 5401.185729054581
prompt_tokens: 256
prompts:
- 'Tell me an extremely long story that starts with the following but goes from there:
  word word word word word word word word word word word word word word word word
  word word word word word word word word word word word word word word word word
  word word word word word word word word word word word word word word word word
  word word word word word word word word word word word word word word word word
  word word word word word word word word word word word word word word word word
  word word word word word word word word word word word word word word word word
  word word word word word word word word word word word word word word word word
  word word word word word word word word word word word word word word word word
  word word word word word word word word word word word word word word word word
  word word word word word word word word '
response_tokens: 128
seconds_to_first_token: 0.047397
token_generation_tokens_per_second: 161.99435297810166
warmup_iterations: 0
