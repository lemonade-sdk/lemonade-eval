backend: llamacpp gpu
checkpoint: Llama-3.2-1B-Instruct-GGUF
iterations: 1
max_memory_used_gbyte: 0.5004081726074219
output_tokens: 64
prefill_tokens_per_second: 5157.962604771116
prompt_tokens: 256
prompts:
- 'Tell me an extremely long story that starts with the following but goes from there:
  word word word word word word word word word word word word word word word word
  word word word word word word word word word word word word word word word word
  word word word word word word word word word word word word word word word word
  word word word word word word word word word word word word word word word word
  word word word word word word word word word word word word word word word word
  word word word word word word word word word word word word word word word word
  word word word word word word word word word word word word word word word word
  word word word word word word word word word word word word word word word word
  word word word word word word word word word word word word word word word word
  word word word word word word word word '
response_tokens: 64
seconds_to_first_token: 0.049631999999999996
token_generation_tokens_per_second: 171.31629806894412
warmup_iterations: 0
